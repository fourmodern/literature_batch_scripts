"""
Generate summaries using Google Gemini API with multimodal support.
"""
import os
import time
import base64
from typing import List, Dict, Optional
import google.generativeai as genai
from text_extractor import encode_image_to_base64

def configure_gemini():
    """Configure Gemini API with API key from environment."""
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable not set")
    genai.configure(api_key=api_key)

def summarize_text_with_retry(text: str, prompt: str, model: str = None, max_tokens: int = 500, max_retries: int = 3) -> str:
    """Generate summary using Gemini API with retry logic for rate limits and errors."""
    if not text or not text.strip():
        return "No text available for summarization."
    
    model_name = model or os.getenv('GEMINI_MODEL', 'gemini-2.5-pro')
    
    configure_gemini()
    model = genai.GenerativeModel(model_name)
    
    # Truncate text if too long
    max_input_length = 800000  # Gemini 1.5 Pro supports ~1M tokens
    if len(text) > max_input_length:
        text = text[:max_input_length] + "... [truncated]"
    
    full_prompt = f"""ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ğŸ”´ ì ˆëŒ€ ê·œì¹™:
1. ì˜¤ì§ ì œê³µëœ ë…¼ë¬¸ í…ìŠ¤íŠ¸ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ë…¼ë¬¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”
3. ë¶ˆí™•ì‹¤í•œ ê²½ìš° ë°˜ë“œì‹œ "ë…¼ë¬¸ì— ëª…ì‹œë˜ì§€ ì•ŠìŒ"ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”
4. ì¼ë°˜ì ì¸ ì§€ì‹ì´ë‚˜ ë°°ê²½ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”
5. ë…¼ë¬¸ì˜ ì‹¤ì œ ë¬¸ì¥ê³¼ ë°ì´í„°ë¥¼ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”

âœ… ì‘ì„± ì›ì¹™:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, í†µê³„, ì‹¤í—˜ ê²°ê³¼ë¥¼ ì •í™•íˆ í¬í•¨
- ì €ìê°€ ì‚¬ìš©í•œ ìš©ì–´ì™€ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ë…¼ë¬¸ì˜ ê° ì„¹ì…˜(Introduction, Methods, Results, Discussion)ì—ì„œ ì •ë³´ ì¶”ì¶œ
- í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±
- í•™ìˆ ì  ì •í™•ì„±ê³¼ ê°ê´€ì„± ìœ ì§€

{prompt}

ë…¼ë¬¸ ë‚´ìš©:
{text}"""
    
    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                full_prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=max_tokens,
                    temperature=0.3,
                )
            )
            
            if response.text:
                return response.text.strip()
            else:
                return "[No response generated]"
        
        except Exception as e:
            if "quota" in str(e).lower() or "rate" in str(e).lower():
                if attempt < max_retries - 1:
                    wait_time = min(2 ** attempt * 5, 60)
                    print(f"Rate limit hit. Waiting {wait_time} seconds before retry...")
                    time.sleep(wait_time)
                else:
                    print(f"Rate limit error after {max_retries} attempts: {e}")
                    return "[Rate limit exceeded - summary unavailable]"
            else:
                if attempt < max_retries - 1:
                    print(f"Error generating summary: {e}. Retrying ({attempt + 1}/{max_retries})...")
                    time.sleep(2)
                else:
                    print(f"Error generating summary after {max_retries} attempts: {e}")
                    return f"[Error generating summary: {type(e).__name__}]"

def summarize_with_images(text: str, images: List[Dict], prompt: str, model: str = None, max_tokens: int = 3000) -> str:
    """Generate summary using text and images with Gemini multimodal capabilities."""
    if not text or not text.strip():
        return "No text available for summarization."
    
    model_name = model or os.getenv('GEMINI_MODEL', 'gemini-1.5-pro')
    
    configure_gemini()
    model = genai.GenerativeModel(model_name)
    
    # Truncate text if too long
    max_input_length = 800000
    if len(text) > max_input_length:
        text = text[:max_input_length] + "... [truncated]"
    
    # Prepare content list with text and images
    content_parts = []
    
    # Add system prompt and text
    full_prompt = f"""ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ì„ ì •í™•í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ì¤‘ìš”í•œ ê·œì¹™:
1. ì œê³µëœ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì— ëª…ì‹œì ìœ¼ë¡œ ë³´ì´ëŠ” ë‚´ìš©ë§Œì„ ìš”ì•½í•˜ì„¸ìš”.
2. ì´ë¯¸ì§€ì˜ ê·¸ë˜í”„, ì°¨íŠ¸, í‘œ, ë‹¤ì´ì–´ê·¸ë¨ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
3. ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚œ ìˆ˜ì¹˜ ë°ì´í„°, íŠ¸ë Œë“œ, íŒ¨í„´ì„ ì •í™•íˆ ì„¤ëª…í•˜ì„¸ìš”.
4. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì¼ê´€ì„± ìˆê²Œ ìš”ì•½í•˜ì„¸ìš”.
5. ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
6. í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

{prompt}

ë…¼ë¬¸ í…ìŠ¤íŠ¸:
{text}

ì•„ë˜ëŠ” ë…¼ë¬¸ì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€ë“¤ì…ë‹ˆë‹¤. ê° ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½ì— í¬í•¨í•˜ì„¸ìš”:"""
    
    content_parts.append(full_prompt)
    
    # Add images (limit to 5 images to avoid token limits and safety issues)
    valid_images = 0
    for i, img_info in enumerate(images[:5]):
        try:
            image_path = img_info['path']
            if os.path.exists(image_path):
                # Read and encode image
                with open(image_path, "rb") as f:
                    image_data = f.read()
                
                # Create image part
                image_part = {
                    'mime_type': 'image/png',
                    'data': image_data
                }
                content_parts.append(f"\n\n[ì´ë¯¸ì§€ {i+1}: í˜ì´ì§€ {img_info['page']}, {img_info['width']}x{img_info['height']}]")
                content_parts.append(image_part)
                valid_images += 1
        except Exception as e:
            print(f"Failed to load image {img_info.get('filename', 'unknown')}: {e}")
            continue
    
    if valid_images == 0:
        print("No valid images found, falling back to text-only summarization")
        return summarize_text_with_retry(text, prompt, model, max_tokens)
    
    print(f"Generating summary with {valid_images} images...")
    
    try:
        # Configure safety settings to be less restrictive for academic content
        safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_NONE"
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_NONE"
            }
        ]
        
        response = model.generate_content(
            content_parts,
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=max_tokens,
                temperature=0.3,
            ),
            safety_settings=safety_settings
        )
        
        if response.text:
            return response.text.strip()
        else:
            # Check for safety blocks or other issues
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'finish_reason'):
                    print(f"Response blocked - Finish reason: {candidate.finish_reason}")
                    if hasattr(candidate, 'safety_ratings'):
                        print(f"Safety ratings: {candidate.safety_ratings}")
            return "[No response generated with images - falling back to text only]"
    
    except Exception as e:
        print(f"Multimodal generation failed: {e}")
        if hasattr(e, '__dict__'):
            print(f"Error details: {e.__dict__}")
        print("Falling back to text-only summarization...")
        return summarize_text_with_retry(text, prompt, model, max_tokens)

def generate_short_long_with_images(text: str, images: List[Dict] = None, captions: List[Dict] = None, title: str = None):
    """Generate both short and long summaries with image analysis."""
    
    # Include captions in text if available
    if captions:
        caption_text = "\n\n=== ì´ë¯¸ì§€ ë° í‘œ ìº¡ì…˜ ===\n"
        for caption in captions:
            caption_text += f"í˜ì´ì§€ {caption['page']}: {caption['text']}\n"
        text = text + caption_text
    
    # Short summary prompt
    short_prompt = """ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ğŸ“‹ ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸:
â–¡ ì—°êµ¬ì˜ êµ¬ì²´ì  ëª©ì  (Introductionì—ì„œ "aim", "objective", "purpose" ì°¾ê¸°)
â–¡ í•µì‹¬ ë°©ë²•ë¡  (Methodsì—ì„œ ì‹¤í—˜ëª…, ëª¨ë¸ëª…, ë°ì´í„°ì…‹ ì°¾ê¸°)
â–¡ ì£¼ìš” ë°œê²¬ (Resultsì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì¹˜ì  ê²°ê³¼ 1-2ê°œ)
â–¡ ì„ìƒì /ê³¼í•™ì  ì˜ì˜ (Discussion/Conclusionì—ì„œ ì €ìì˜ ì£¼ì¥)

âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­:
- ë…¼ë¬¸ê³¼ ì´ë¯¸ì§€ì— ì§ì ‘ ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš© (í˜ì´ì§€ë‚˜ ì„¹ì…˜ ì°¸ì¡° ê°€ëŠ¥)
- êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨ (ì˜ˆ: "50% ê°ì†Œ", "p<0.001", "n=100")
- ì €ìê°€ ì‚¬ìš©í•œ ì •í™•í•œ ìš©ì–´ ì‚¬ìš© (ì•½ë¬¼ëª…, ë‹¨ë°±ì§ˆëª…, ì§ˆë³‘ëª… ë“±)
- ë°°ê²½ì§€ì‹ì´ë‚˜ ì¼ë°˜ì  ì„¤ëª… ì¶”ê°€ ê¸ˆì§€
- ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” ìƒëµ (ì–µì§€ë¡œ ì±„ìš°ì§€ ë§ ê²ƒ)

í˜•ì‹: ê° ë¬¸ì¥ì€ ë…¼ë¬¸ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë£¨ë©°, êµ¬ì²´ì ì´ê³  ì •ë³´ê°€ í’ë¶€í•´ì•¼ í•¨"""
    
    # Long summary prompt
    long_prompt = """ì´ ë…¼ë¬¸ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ í•™ìˆ  ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ“š **ìš”ì•½ ì‘ì„± ì§€ì¹¨**

**1. ì—°êµ¬ ë°°ê²½ ë° í•„ìš”ì„±** (Introduction ì„¹ì…˜ ê¸°ë°˜)
â–¡ í•´ê²°í•˜ë ¤ëŠ” êµ¬ì²´ì  ë¬¸ì œ (ì €ìê°€ ì œì‹œí•œ research gap)
â–¡ ê¸°ì¡´ ì—°êµ¬ì˜ í•œê³„ (ë…¼ë¬¸ì—ì„œ ì¸ìš©í•œ ì„ í–‰ì—°êµ¬ì™€ ê·¸ í•œê³„ì )
â–¡ ì´ ì—°êµ¬ì˜ í•„ìš”ì„± (ì €ìì˜ rationale)
â–¡ ëª…í™•í•œ ì—°êµ¬ ëª©ì /ê°€ì„¤ ("We hypothesized...", "This study aims..." ë¬¸ì¥ ì°¾ê¸°)

**2. ì—°êµ¬ ì„¤ê³„ ë° ë°©ë²•ë¡ ** (Methods/Materials ì„¹ì…˜ ê¸°ë°˜)
â–¡ ì—°êµ¬ ë””ìì¸ (RCT, cohort, case-control, in vitro, in vivo ë“±)
â–¡ ëŒ€ìƒ/ìƒ˜í”Œ (í™˜ììˆ˜, ì„¸í¬ì£¼, ë™ë¬¼ëª¨ë¸ - êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)
â–¡ ì£¼ìš” ì‹¤í—˜ ë°©ë²•/í”„ë¡œí† ì½œ (ì‚¬ìš©ëœ ê¸°ë²•ëª…, ì¥ë¹„, ì‹œì•½)
â–¡ í†µê³„ ë¶„ì„ ë°©ë²• (ì‚¬ìš©ëœ ê²€ì •ë²•, ìœ ì˜ìˆ˜ì¤€)
â–¡ ì¤‘ìš” íŒŒë¼ë¯¸í„°/ì¡°ê±´ (ë†ë„, ì‹œê°„, ì˜¨ë„ ë“±)
â–¡ ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚œ ì‹¤í—˜ ì„¤ê³„ë„ë‚˜ ì›Œí¬í”Œë¡œìš°

**3. í•µì‹¬ ì—°êµ¬ ê²°ê³¼** (Results ì„¹ì…˜ + Figures/Tables ê¸°ë°˜)
â–¡ Primary outcome (ì£¼ìš” ê²°ê³¼ë¥¼ ìˆ˜ì¹˜ì™€ í•¨ê»˜)
â–¡ Secondary outcomes (ë¶€ê°€ì  ë°œê²¬ì‚¬í•­)
â–¡ í†µê³„ì  ìœ ì˜ì„± (p-values, CI, effect size)
â–¡ ì˜ˆìƒì¹˜ ëª»í•œ ë°œê²¬ (ë…¼ë¬¸ì— ëª…ì‹œëœ ê²½ìš°)
â–¡ Figure/Tableì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë°ì´í„° 2-3ê°œ ì¸ìš©
â–¡ ì´ë¯¸ì§€ì˜ ê·¸ë˜í”„/ì°¨íŠ¸ì—ì„œ ì¶”ì¶œí•œ êµ¬ì²´ì  ìˆ˜ì¹˜

**4. ê²°ê³¼ì˜ í•´ì„ ë° ì˜ì˜** (Discussion ì„¹ì…˜ ê¸°ë°˜)
â–¡ ì €ìì˜ ì£¼ìš” í•´ì„ ("Our findings suggest...", "This indicates...")
â–¡ ê¸°ì¡´ ì—°êµ¬ì™€ì˜ ì¼ì¹˜/ë¶ˆì¼ì¹˜ì  (ì €ìê°€ ë¹„êµí•œ ë‚´ìš©)
â–¡ ë©”ì»¤ë‹ˆì¦˜ ì„¤ëª… (ì €ìê°€ ì œì•ˆí•œ ê²½ìš°)
â–¡ ì„ìƒì /ê³¼í•™ì  í•¨ì˜ (ì €ìê°€ ì£¼ì¥í•˜ëŠ” impact)

**5. ì—°êµ¬ì˜ ê°•ì ê³¼ í•œê³„** (Discussion/Limitations ì„¹ì…˜ ê¸°ë°˜)
â–¡ ì €ìê°€ ì œì‹œí•œ ì—°êµ¬ì˜ ê°•ì 
â–¡ ì €ìê°€ ì¸ì •í•œ í•œê³„ì  ("limitation", "weakness" í‚¤ì›Œë“œ)
â–¡ í–¥í›„ ì—°êµ¬ ë°©í–¥ ("future studies", "further research" ë¬¸ì¥)

âš ï¸ **ì ˆëŒ€ ì¤€ìˆ˜ì‚¬í•­:**
- ê° í•­ëª©ë³„ë¡œ ë…¼ë¬¸ì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "[í•´ë‹¹ ë‚´ìš© ë…¼ë¬¸ì— ëª…ì‹œë˜ì§€ ì•ŠìŒ]" í‘œê¸°
- ëª¨ë“  ìˆ˜ì¹˜ëŠ” ì •í™•íˆ ì¸ìš© (ë°˜ì˜¬ë¦¼í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ ê²ƒ)
- ì €ìê°€ ì‚¬ìš©í•œ ì „ë¬¸ìš©ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ë…¼ë¬¸ ì™¸ë¶€ì˜ ì§€ì‹ìœ¼ë¡œ ë³´ì¶©í•˜ì§€ ë§ ê²ƒ
- ê° ì„¹ì…˜ë§ˆë‹¤ ìµœì†Œ 2-3ê°œì˜ êµ¬ì²´ì  ì •ë³´ í¬í•¨"""
    
    # Add title context if available
    if title:
        short_prompt = f"Paper Title: {title}\n\n{short_prompt}"
        long_prompt = f"Paper Title: {title}\n\n{long_prompt}"
    
    # Use multimodal if images are available
    if images and len(images) > 0:
        short = summarize_with_images(text, images, short_prompt, max_tokens=400)
        long = summarize_with_images(text, images, long_prompt, max_tokens=3000)
    else:
        short = summarize_text_with_retry(text, short_prompt, max_tokens=400)
        long = summarize_text_with_retry(text, long_prompt, max_tokens=3000)
    
    return short, long

def generate_sections_with_images(text: str, images: List[Dict] = None, captions: List[Dict] = None, title: str = None):
    """Generate specific sections like contributions, limitations, ideas, and keywords with image analysis."""
    
    # Include captions in text if available
    if captions:
        caption_text = "\n\n=== ì´ë¯¸ì§€ ë° í‘œ ìº¡ì…˜ ===\n"
        for caption in captions:
            caption_text += f"í˜ì´ì§€ {caption['page']}: {caption['text']}\n"
        text = text + caption_text
    
    contribution_prompt = """ë…¼ë¬¸ì—ì„œ ì €ìê°€ ì£¼ì¥í•˜ëŠ” í•µì‹¬ ê¸°ì—¬ë„(contributions)ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ğŸ” **ì°¾ì•„ì•¼ í•  ë‚´ìš©:**
1. **ëª…ì‹œì  ê¸°ì—¬ë„ ì„ ì–¸**
   - "Our contributions are...", "We contribute...", "This paper makes the following contributions..."
   - "For the first time...", "Novel...", "We are the first to..."
   - "We demonstrate...", "We show...", "We establish..."

2. **ê³¼í•™ì  ë°œê²¬**
   - ìƒˆë¡œìš´ ë©”ì»¤ë‹ˆì¦˜, ê²½ë¡œ, ê´€ê³„ì„±
   - ê¸°ì¡´ ì´ë¡ ì˜ í™•ì¥ ë˜ëŠ” ë°˜ë°•
   - ìƒˆë¡œìš´ ë°”ì´ì˜¤ë§ˆì»¤, íƒ€ê²Ÿ, ì¹˜ë£Œë²•
   - ì´ë¯¸ì§€ì—ì„œ ë³´ì—¬ì£¼ëŠ” í˜ì‹ ì  ê²°ê³¼

3. **ë°©ë²•ë¡ ì  í˜ì‹ **
   - ìƒˆë¡œìš´ ì‹¤í—˜ ê¸°ë²•, ë¶„ì„ ë°©ë²•
   - ê¸°ì¡´ ë°©ë²•ì˜ ê°œì„ 
   - ìƒˆë¡œìš´ ëª¨ë¸, ì•Œê³ ë¦¬ì¦˜, í”„ë¡œí† ì½œ

4. **ì„ìƒì /ì‹¤ìš©ì  ê¸°ì—¬**
   - ì§„ë‹¨, ì¹˜ë£Œ, ì˜ˆí›„ì— ëŒ€í•œ ìƒˆë¡œìš´ í†µì°°
   - ê°€ì´ë“œë¼ì¸ ë³€ê²½ ì œì•ˆ
   - ì‹¤ì œ ì ìš© ê°€ëŠ¥ì„±

ğŸ“ **ì‘ì„± í˜•ì‹:**
â€¢ [ê¸°ì—¬ ìœ í˜•]: êµ¬ì²´ì  ë‚´ìš© (ë…¼ë¬¸ì˜ ì •í™•í•œ í‘œí˜„ ì¸ìš©)
â€¢ ê° ê¸°ì—¬ë„ëŠ” bullet pointë¡œ êµ¬ë¶„
â€¢ ì €ìì˜ ì›ë¬¸ í‘œí˜„ì„ ìµœëŒ€í•œ ë³´ì¡´
â€¢ ì´ë¯¸ì§€ì—ì„œ ì…ì¦ëœ ê¸°ì—¬ë„ë„ í¬í•¨

âš ï¸ ë…¼ë¬¸ì—ì„œ ëª…í™•í•œ ê¸°ì—¬ë„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°:
"ì €ìê°€ ëª…ì‹œì ìœ¼ë¡œ ê¸°ìˆ í•œ ê¸°ì—¬ë„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. Discussion/Conclusionì—ì„œë„ ëª…í™•í•œ contribution statement ë¶€ì¬."""
    
    limitations_prompt = """ë…¼ë¬¸ì—ì„œ ì €ìê°€ ì¸ì •í•œ ì—°êµ¬ì˜ í•œê³„ì (limitations)ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.

ğŸ” **íƒìƒ‰ ì „ëµ:**
1. **í‚¤ì›Œë“œ ê²€ìƒ‰**
   - "limitation", "limited", "constraint", "shortcoming"
   - "weakness", "drawback", "caveat", "challenge"
   - "could not", "unable to", "failed to", "did not"
   - "should be interpreted with caution", "preliminary"

2. **ì¼ë°˜ì  ìœ„ì¹˜**
   - Discussion í›„ë°˜ë¶€
   - Conclusion ì„¹ì…˜
   - "Study Limitations" ë³„ë„ ì„¹ì…˜
   - Results ì„¹ì…˜ì˜ í•´ì„ ì£¼ì˜ ë¬¸êµ¬

3. **í•œê³„ì  ìœ í˜•**
   â–¡ ìƒ˜í”Œ ê´€ë ¨ (í¬ê¸°, ëŒ€í‘œì„±, ì„ íƒ í¸í–¥)
   â–¡ ë°©ë²•ë¡ ì  í•œê³„ (ë””ìì¸, ì¸¡ì •, ë¶„ì„)
   â–¡ ì‹œê°„ì /ê³µê°„ì  ì œì•½
   â–¡ ì¼ë°˜í™” ê°€ëŠ¥ì„± ì œí•œ
   â–¡ ë°ì´í„° ë¶ˆì™„ì „ì„±
   â–¡ ê¸°ìˆ ì  ì œì•½
   â–¡ ì´ë¯¸ì§€ í’ˆì§ˆì´ë‚˜ í•´ìƒë„ ë¬¸ì œ

ğŸ“ **ì‘ì„± í˜•ì‹:**
â€¢ [í•œê³„ ìœ í˜•]: êµ¬ì²´ì  ë‚´ìš© (ì €ìì˜ ì›ë¬¸ í‘œí˜„)
â€¢ ê° í•œê³„ì ì´ ê²°ê³¼ í•´ì„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ (ì €ìê°€ ì–¸ê¸‰í•œ ê²½ìš°)
â€¢ ì €ìê°€ ì œì‹œí•œ ë³´ì™„ ë°©ë²• (ìˆëŠ” ê²½ìš°)

âš ï¸ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°:
"ì €ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•œ ì—°êµ¬ í•œê³„ì ì„ Discussion, Conclusion, ë˜ëŠ” ë³„ë„ Limitations ì„¹ì…˜ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ."""
    
    ideas_prompt = """ë…¼ë¬¸ì—ì„œ ì €ìê°€ ì œì‹œí•œ í–¥í›„ ì—°êµ¬ ë°©í–¥ê³¼ ë¯¸í•´ê²° ì§ˆë¬¸ë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ğŸ” **íƒìƒ‰ í‚¤ì›Œë“œ:**
1. **ì§ì ‘ì  ì œì•ˆ**
   - "future studies/research/work should..."
   - "it would be interesting/important to..."
   - "further investigation is needed/warranted"
   - "remains to be determined/elucidated/investigated"

2. **ë¯¸í•´ê²° ì§ˆë¬¸**
   - "unclear", "unknown", "not fully understood"
   - "warrants further study", "merits investigation"
   - "open question", "unanswered", "yet to be"

3. **í™•ì¥ ê°€ëŠ¥ì„±**
   - "could be extended to", "may be applied to"
   - "potential for", "promising avenue"
   - "next step", "logical extension"

ğŸ“‹ **ë¶„ë¥˜ ì²´ê³„:**
**A. ì¦‰ì‹œ ê°€ëŠ¥í•œ ì—°êµ¬**
- í˜„ì¬ ê¸°ìˆ /ë°©ë²•ìœ¼ë¡œ ìˆ˜í–‰ ê°€ëŠ¥í•œ ì—°êµ¬

**B. ì¥ê¸°ì  ì—°êµ¬ ë°©í–¥**
- ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•œ ì—°êµ¬

**C. ì„ìƒ ì ìš© ì—°êµ¬**
- ë²ˆì—­ ì—°êµ¬, ì„ìƒì‹œí—˜ ì œì•ˆ

**D. ë©”ì»¤ë‹ˆì¦˜ ê·œëª…**
- ë” ê¹Šì€ ì´í•´ê°€ í•„ìš”í•œ ë¶€ë¶„

ğŸ“ **ì‘ì„± í˜•ì‹:**
â€¢ [ì¹´í…Œê³ ë¦¬]: êµ¬ì²´ì  ì œì•ˆ ë‚´ìš© (ì €ìì˜ ì›ë¬¸ ì¸ìš©)
â€¢ ê° ì œì•ˆì˜ ê·¼ê±°ë‚˜ ì¤‘ìš”ì„± (ì €ìê°€ ì–¸ê¸‰í•œ ê²½ìš°)

âš ï¸ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°:
"ì €ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì œì•ˆí•œ í–¥í›„ ì—°êµ¬ ë°©í–¥ì´ë‚˜ ë¯¸ë˜ ê³¼ì œë¥¼ Discussion ë˜ëŠ” Conclusionì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ."""
    
    keywords_prompt = """ì´ ë…¼ë¬¸ì—ì„œ ë‹¤ë¥¸ ë…¼ë¬¸ê³¼ ì—°ê²°í•  ìˆ˜ ìˆëŠ” í•µì‹¬ í‚¤ì›Œë“œ 5-8ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ë¡œ ë‚˜ì—´í•˜ì„¸ìš”.

ğŸ¯ **í‚¤ì›Œë“œ ì„ íƒ ê¸°ì¤€:**
ë‹¤ë¥¸ ë…¼ë¬¸ì—ì„œë„ ê³µí†µìœ¼ë¡œ ì‚¬ìš©ë  ë§Œí•œ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:

1. **í•µì‹¬ ê°œë…** (2-3ê°œ)
   - ì§ˆë³‘ëª…: diabetes, cancer, alzheimer
   - ì—°êµ¬ë¶„ì•¼: immunology, neuroscience, metabolism
   - í•µì‹¬ê¸°ìˆ : crispr, proteomics, single-cell

2. **íŠ¹ì • ìš©ì–´** (2-3ê°œ)  
   - ë‹¨ë°±ì§ˆ/ìœ ì „ì: p53, tnf, jak2
   - ì•½ë¬¼: metformin, aspirin, tofacitinib
   - ê²½ë¡œ: nf-kb, mapk, jak-stat

3. **ë°©ë²•ë¡ ** (1-2ê°œ)
   - rna-seq, western-blot, flow-cytometry
   - clinical-trial, meta-analysis, cohort-study

ğŸ“ **í˜•ì‹:**
- ì˜ì–´ ì†Œë¬¸ì
- í•˜ì´í”ˆìœ¼ë¡œ ì—°ê²° (jak-stat, rna-seq)
- ê°„ë‹¨í•˜ê³  ëª…í™•í•œ ë‹¨ì–´
- **ë°˜ë“œì‹œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ë¡œ ë‚˜ì—´**
- ì˜ˆ: machine-learning, deep-neural-networks, computer-vision, image-classification
- ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚œ í•µì‹¬ ìš©ì–´ë„ ê³ ë ¤

âš ï¸ ì£¼ì˜:
- ë„ˆë¬´ êµ¬ì²´ì ì¸ ìš©ì–´ íšŒí”¼ (ì˜ˆ: "jak2-v617f-mutation" â†’ "jak2")
- ì¼ë°˜ì  ë‹¨ì–´ íšŒí”¼ (study, research, analysis)
- ë…¼ë¬¸ ì œëª©ì˜ íŠ¹ìˆ˜í•œ ë¬¸êµ¬ íšŒí”¼"""
    
    # Use multimodal if images are available
    if images and len(images) > 0:
        contributions = summarize_with_images(text, images, contribution_prompt, max_tokens=500)
        limitations = summarize_with_images(text, images, limitations_prompt, max_tokens=500)
        ideas = summarize_with_images(text, images, ideas_prompt, max_tokens=500)
        keywords = summarize_with_images(text, images, keywords_prompt, max_tokens=200)
    else:
        contributions = summarize_text_with_retry(text, contribution_prompt, max_tokens=500)
        limitations = summarize_text_with_retry(text, limitations_prompt, max_tokens=500)
        ideas = summarize_text_with_retry(text, ideas_prompt, max_tokens=500)
        keywords = summarize_text_with_retry(text, keywords_prompt, max_tokens=200)
    
    return contributions, limitations, ideas, keywords

# Keep compatibility with existing code
def summarize_text(text: str, prompt: str, model: str = None, max_tokens: int = 500) -> str:
    """Generate summary using Gemini API with custom prompt."""
    return summarize_text_with_retry(text, prompt, model, max_tokens)

def generate_short_long(text: str, title: str = None):
    """Generate both short and long summaries (text-only for backward compatibility)."""
    return generate_short_long_with_images(text, None, None, title)

def generate_sections(text: str, title: str = None):
    """Generate specific sections (text-only for backward compatibility)."""
    return generate_sections_with_images(text, None, None, title)

if __name__ == '__main__':
    import sys
    txt = sys.stdin.read()
    s, l = generate_short_long(txt, "Test Paper")
    print("---SHORT SUMMARY---\n", s)
    print("\n---LONG SUMMARY---\n", l)