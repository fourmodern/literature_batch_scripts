"""
Generate summaries using OpenAI API with retry logic.
- ì£¼ìš” ìˆ˜ì •:
  * stdin ë¸”ë¡œí‚¹ ë°©ì§€
  * chat.completions íŒŒë¼ë¯¸í„°: max_completion_tokens â†’ max_tokens
  * timeoutì€ í´ë¼ì´ì–¸íŠ¸ ì˜µì…˜ìœ¼ë¡œ ì§€ì •
  * ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ë¦¬
"""

import os
import time
import sys
from typing import List, Dict

from openai import OpenAI
# ì˜ˆì™¸ëŠ” ìƒí™©ë³„ë¡œ ì„¸ë¶„í™”í•´ ì²˜ë¦¬
from openai import (
    RateLimitError, APITimeoutError, APIConnectionError,
    APIError, BadRequestError, AuthenticationError, InternalServerError
)


def summarize_text_with_retry(
    text: str,
    prompt: str,
    model: str = None,
    max_tokens: int = 500,
    max_retries: int = 3,
    request_timeout: int = 300,  # 5ë¶„ìœ¼ë¡œ ì¦ê°€
) -> str:
    """
    Generate summary using OpenAI API with retry logic for rate limits and errors.
    - text: ìš”ì•½ ëŒ€ìƒ ì›ë¬¸
    - prompt: ì‹œìŠ¤í…œ/ì‚¬ìš©ì ì§€ì‹œ
    - model: ëª¨ë¸ëª… (ë¯¸ì§€ì • ì‹œ í™˜ê²½ë³€ìˆ˜ MODEL ë˜ëŠ” ê¸°ë³¸ê°’ 'gpt-5-mini')
    - max_tokens: ì¶œë ¥ í† í° ìƒí•œ (chat.completions: max_tokens)
    - max_retries: ìˆ˜ë™ ì¬ì‹œë„ íšŸìˆ˜
    - request_timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ì´ˆ)
    """
    if not text or not text.strip():
        return "No text available for summarization."

    model = model or os.getenv("MODEL", "gpt-4o")

    # í´ë¼ì´ì–¸íŠ¸ì— timeout ì§€ì • (ìš”ì²­ë§ˆë‹¤ timeoutì„ ì£¼ê³  ì‹¶ë‹¤ë©´ with_options ì‚¬ìš©)
    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        max_retries=0,           # ìˆ˜ë™ ì¬ì‹œë„ ì œì–´
        timeout=request_timeout, # ì „ì²´ ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 5ë¶„)
    )

    # ë§¤ìš° ê¸´ ì…ë ¥ì˜ ë³´ìˆ˜ì  íŠ¸ë ì¼€ì´ì…˜ (ë¬¸ì ê¸¸ì´ ê¸°ì¤€; ì‹¤ì œ í† í°ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    max_input_length = 30000  # ~7.5k í† í° ìˆ˜ì¤€ ê°€ì •
    if len(text) > max_input_length:
        text = text[:max_input_length] + "... [truncated]"

    messages = [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ìµœê³  ìˆ˜ì¤€ì˜ í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
                "ğŸ”´ ì ˆëŒ€ ê·œì¹™:\n"
                "1. ì˜¤ì§ ì œê³µëœ ë…¼ë¬¸ í…ìŠ¤íŠ¸ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n"
                "2. ë…¼ë¬¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”\n"
                "3. ë¶ˆí™•ì‹¤í•œ ê²½ìš° ë°˜ë“œì‹œ \"ë…¼ë¬¸ì— ëª…ì‹œë˜ì§€ ì•ŠìŒ\"ìœ¼ë¡œ í‘œê¸°í•˜ì„¸ìš”\n"
                "4. ì¼ë°˜ì ì¸ ì§€ì‹ì´ë‚˜ ë°°ê²½ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n"
                "5. ë…¼ë¬¸ì˜ ì‹¤ì œ ë¬¸ì¥ê³¼ ë°ì´í„°ë¥¼ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”\n\n"
                "âœ… ì‘ì„± ì›ì¹™:\n"
                "- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, í†µê³„, ì‹¤í—˜ ê²°ê³¼ë¥¼ ì •í™•íˆ í¬í•¨\n"
                "- ì €ìê°€ ì‚¬ìš©í•œ ìš©ì–´ì™€ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n"
                "- ë…¼ë¬¸ì˜ ê° ì„¹ì…˜(Introduction, Methods, Results, Discussion)ì—ì„œ ì •ë³´ ì¶”ì¶œ\n"
                "- í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±\n"
                "- í•™ìˆ ì  ì •í™•ì„±ê³¼ ê°ê´€ì„± ìœ ì§€"
            ),
        },
        {
            "role": "user",
            "content": f"{prompt}\n\në…¼ë¬¸ ë‚´ìš©:\n{text}",
        },
    ]

    for attempt in range(max_retries):
        try:
            # gpt-5 ì‹œë¦¬ì¦ˆëŠ” Responses API ì‚¬ìš©
            if 'gpt-5' in model:
                resp = client.responses.create(
                    model=model,
                    input=messages,
                    max_output_tokens=max_tokens,
                    reasoning={"effort": "minimal"},  # ë‚´ë¶€ ì¶”ë¡  ìµœì†Œí™”
                )
                # Responseì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text_parts = []
                for output_item in resp.output:
                    if hasattr(output_item, 'content'):
                        for content_item in output_item.content:
                            if hasattr(content_item, 'text'):
                                text_parts.append(content_item.text)
                return ''.join(text_parts).strip()
            else:
                resp = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens,
                )
                return resp.choices[0].message.content.strip()

        except RateLimitError as e:
            # 429 â†’ ì§€ìˆ˜ ë°±ì˜¤í”„
            if attempt < max_retries - 1:
                wait = min(5 * (2**attempt), 60)
                print(f"[RateLimit] Waiting {wait}s... ({attempt+1}/{max_retries})")
                time.sleep(wait)
                continue
            return "[Rate limit exceeded - summary unavailable]"

        except (APITimeoutError,) as e:
            if attempt < max_retries - 1:
                print(f"[Timeout] Retrying... ({attempt+1}/{max_retries})")
                time.sleep(2)
                continue
            return "[API timeout - summary unavailable]"

        except (APIConnectionError,) as e:
            if attempt < max_retries - 1:
                print(f"[Connection] {e} â†’ retry ({attempt+1}/{max_retries})")
                time.sleep(2)
                continue
            return "[Connection error - summary unavailable]"

        except (BadRequestError, AuthenticationError) as e:
            # 400/401 ë²”ì£¼ â†’ ì¬ì‹œë„ ë¬´ì˜ë¯¸
            return f"[Request error - {type(e).__name__}]"

        except (InternalServerError, APIError) as e:
            # 5xx ë˜ëŠ” ê¸°íƒ€ APIError â†’ 1~2íšŒ ì¬ì‹œë„ í›„ ì¤‘ë‹¨
            if attempt < max_retries - 1:
                print(f"[Server/APIError] retry ({attempt+1}/{max_retries})")
                time.sleep(2)
                continue
            return f"[API error - {type(e).__name__}]"

        except Exception as e:
            if attempt < max_retries - 1:
                print(f"[Unexpected] {e} â†’ retry ({attempt+1}/{max_retries})")
                time.sleep(2)
                continue
            return f"[Error generating summary: {type(e).__name__}]"


def summarize_text(text: str, prompt: str, model: str = None, max_tokens: int = 500) -> str:
    """Backward compatibility wrapper."""
    return summarize_text_with_retry(text, prompt, model, max_tokens)


def generate_short_long(text: str, title: str = None):
    """Generate both short and long summaries of the text."""
    short_prompt = (
        "ì´ ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ì •í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n\n"
        "ğŸ“‹ ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸:\n"
        "â–¡ ì—°êµ¬ì˜ êµ¬ì²´ì  ëª©ì  (Introductionì—ì„œ 'aim', 'objective', 'purpose' ì°¾ê¸°)\n"
        "â–¡ í•µì‹¬ ë°©ë²•ë¡  (Methodsì—ì„œ ì‹¤í—˜ëª…, ëª¨ë¸ëª…, ë°ì´í„°ì…‹ ì°¾ê¸°)\n"
        "â–¡ ì£¼ìš” ë°œê²¬ (Resultsì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì¹˜ì  ê²°ê³¼ 1-2ê°œ)\n"
        "â–¡ ì„ìƒì /ê³¼í•™ì  ì˜ì˜ (Discussion/Conclusionì—ì„œ ì €ìì˜ ì£¼ì¥)\n\n"
        "âš ï¸ í•„ìˆ˜ ì¤€ìˆ˜ì‚¬í•­:\n"
        "- ë…¼ë¬¸ì— ì§ì ‘ ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©\n"
        "- êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨\n"
        "- ì €ìì˜ ì •í™•í•œ ìš©ì–´ ì‚¬ìš©\n"
        "- ë°°ê²½ì§€ì‹ ì¶”ê°€ ê¸ˆì§€\n"
        "- ì°¾ì„ ìˆ˜ ì—†ëŠ” ì •ë³´ëŠ” ìƒëµ\n"
        "í˜•ì‹: ê° ë¬¸ì¥ì€ ë…¼ë¬¸ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë£¨ë©°, êµ¬ì²´ì ì´ê³  ì •ë³´ê°€ í’ë¶€í•´ì•¼ í•¨"
    )

    long_prompt = (
        "ì´ ë…¼ë¬¸ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬ ìƒì„¸í•œ í•™ìˆ  ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
        "1) ì—°êµ¬ ë°°ê²½ ë° í•„ìš”ì„±\n"
        "2) ì—°êµ¬ ì„¤ê³„ ë° ë°©ë²•ë¡ \n"
        "3) í•µì‹¬ ì—°êµ¬ ê²°ê³¼\n"
        "4) ê²°ê³¼ í•´ì„ ë° ì˜ì˜\n"
        "5) ì—°êµ¬ì˜ ê°•ì ê³¼ í•œê³„\n"
        "âš ï¸ ê° í•­ëª©ë³„ë¡œ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ '[í•´ë‹¹ ë‚´ìš© ë…¼ë¬¸ì— ëª…ì‹œë˜ì§€ ì•ŠìŒ]' í‘œê¸°"
    )

    if title:
        short_prompt = f"Paper Title: {title}\n\n{short_prompt}"
        long_prompt = f"Paper Title: {title}\n\n{long_prompt}"

    # GPT-5-miniëŠ” ë” ë§ì€ í† í°ì´ í•„ìš” (Responses API ì‚¬ìš© ì‹œ)
    model = os.getenv("MODEL", "gpt-4o-mini")
    # GPT-5ëŠ” Responses APIë¡œ ì¶©ë¶„í•œ ì¶œë ¥ í† í° í™•ë³´
    if 'gpt-5' in model:
        short_tokens = 1200  # ê°„ë‹¨ ìš”ì•½ìš©
        long_tokens = 2000   # ìƒì„¸ ìš”ì•½ìš©
    else:
        short_tokens = 400
        long_tokens = 3000
    
    short = summarize_text(text, short_prompt, max_tokens=short_tokens)
    long = summarize_text(text, long_prompt, max_tokens=long_tokens)
    return short, long


def generate_sections(text: str, title: str = None):
    """Generate contributions, limitations, ideas, keywords."""
    # title íŒŒë¼ë¯¸í„° í™œìš©
    prefix = f"Paper Title: {title}\n\n" if title else ""
    
    contribution_prompt = prefix + "ë…¼ë¬¸ ê¸°ì—¬ë„ë¥¼ bulletë¡œ ì •ë¦¬. ì›ë¬¸ í‘œí˜„ì„ ìµœëŒ€í•œ ë³´ì¡´."
    limitations_prompt = prefix + "ë…¼ë¬¸ í•œê³„ì ì„ ì •ë¦¬. ì›ë¬¸ ì¸ìš© í¬í•¨."
    ideas_prompt = prefix + "í–¥í›„ ì—°êµ¬ ë°©í–¥/ë¯¸í•´ê²° ì§ˆë¬¸ì„ ë¶„ë¥˜(A/B/C/D)í•˜ì—¬ ì •ë¦¬."
    keywords_prompt = prefix + "ë‹¤ë¥¸ ë…¼ë¬¸ê³¼ ì—°ê²° ê°€ëŠ¥í•œ í•µì‹¬ í‚¤ì›Œë“œ 5-8ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´(ì†Œë¬¸ì, í•˜ì´í”ˆ ì‚¬ìš©). ì˜ˆ: machine-learning, deep-neural-networks, computer-vision"

    # GPT-5-miniëŠ” Responses APIë¡œ ì ì ˆí•œ í† í° ì„¤ì •
    model = os.getenv("MODEL", "gpt-4o-mini")
    if 'gpt-5' in model:
        section_tokens = 1500  # ì„¹ì…˜ë³„ ìš”ì•½ìš©
        keyword_tokens = 500   # í‚¤ì›Œë“œìš©
    else:
        section_tokens = 500
        keyword_tokens = 200
    
    contributions = summarize_text(text, contribution_prompt, max_tokens=section_tokens)
    limitations = summarize_text(text, limitations_prompt, max_tokens=section_tokens)
    ideas = summarize_text(text, ideas_prompt, max_tokens=section_tokens)
    keywords = summarize_text(text, keywords_prompt, max_tokens=keyword_tokens)
    return contributions, limitations, ideas, keywords


def translate_captions(captions: List[Dict], caption_type: str = "figure") -> List[Dict]:
    """Translate figure/table captions to Korean."""
    import logging
    log = logging.getLogger(__name__)

    if not captions:
        return captions

    client = OpenAI(timeout=60)  # ë²ˆì—­ì€ ë” ì§§ì€ íƒ€ì„ì•„ì›ƒ

    translated = []
    for cap in captions:
        title = cap.get("title", "")
        if not title:
            translated.append(cap)
            continue

        full_prompt = (
            f"ë‹¤ìŒ ë…¼ë¬¸ {'ê·¸ë¦¼' if caption_type == 'figure' else 'í‘œ'} ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­.\n"
            f"ì „ë¬¸ìš©ì–´ëŠ” ì˜ì–´ ë³‘ê¸°.\n\nì›ë¬¸: {title}\n\n"
            "ë²ˆì—­ëœ í•œêµ­ì–´ ì œëª©ë§Œ ì¶œë ¥:"
        )
        try:
            # ë²ˆì—­ì€ í•­ìƒ gpt-4o-mini ì‚¬ìš© (ë¹ ë¥´ê³  ì €ë ´)
            resp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional academic translator."},
                    {"role": "user", "content": full_prompt},
                ],
                max_tokens=200,  # gpt-4o-miniëŠ” max_tokens ì‚¬ìš©
            )
            title_kr = resp.choices[0].message.content.strip()
        except Exception as e:
            # API í• ë‹¹ëŸ‰ ì´ˆê³¼ ë“±ì˜ ì—ëŸ¬ ì‹œ ì›ë¬¸ ì‚¬ìš©
            if "insufficient_quota" in str(e):
                log.warning(f"API quota exceeded - using original title")
            else:
                log.warning(f"Translation failed for '{title[:50]}...': {e}")
            title_kr = title

        new_cap = cap.copy()
        new_cap["title_kr"] = title_kr
        translated.append(new_cap)

    return translated


if __name__ == "__main__":
    # í‘œì¤€ì…ë ¥ ë¸”ë¡œí‚¹ ë°©ì§€: íŒŒì´í”„ ì…ë ¥ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€ ë˜ëŠ” ìƒ˜í”Œ ì²˜ë¦¬
    if sys.stdin.isatty():
        # a) íŒŒì¼ ê²½ë¡œ ì¸ìë¥¼ ë°›ëŠ” ë°©ì‹
        if len(sys.argv) >= 2 and os.path.exists(sys.argv[1]):
            with open(sys.argv[1], "r", encoding="utf-8") as f:
                txt = f.read()
        else:
            # b) ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì‚¬ìš©ë²• ì•ˆë‚´ í›„ ì¢…ë£Œ
            print("Usage: python script.py < paper.txt  ë˜ëŠ”  python script.py paper.txt")
            sys.exit(1)
    else:
        txt = sys.stdin.read()

    s, l = generate_short_long(txt, "Test Paper")
    print("---SHORT SUMMARY---\n", s)
    print("\n---LONG SUMMARY---\n", l)
