"""
Multimodal RAG Builder with CLIP
ì§„ì •í•œ ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ì„ ìœ„í•œ ê°œì„ ëœ êµ¬í˜„
"""

import os
import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import numpy as np
from PIL import Image
import chromadb
from dotenv import load_dotenv
import google.generativeai as genai
import base64

load_dotenv()

class MultimodalRAGBuilder:
    """ë©€í‹°ëª¨ë‹¬ RAG ì‹œìŠ¤í…œ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•© ê²€ìƒ‰)"""

    def __init__(self, use_pinecone: bool = True):
        from sentence_transformers import SentenceTransformer

        # CLIP ViT-B-32 ì‚¬ìš© (ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ëª¨ë¸)
        # Jina CLIPì€ custom_st ëª¨ë“ˆ í•„ìš”ë¡œ ì„¤ì¹˜ ë³µì¡
        self.model = SentenceTransformer('clip-ViT-B-32')
        print("âœ… CLIP ViT-B-32 ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ë¡œë“œ")
        print("   - ì§„ì§œ ë©€í‹°ëª¨ë‹¬: ì´ë¯¸ì§€ í”½ì…€ì„ ì§ì ‘ ì„ë² ë”©")
        print("   - í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ê°€ ê°™ì€ 512ì°¨ì› ê³µê°„ì— ë§¤í•‘")
        print("   - í¬ë¡œìŠ¤ëª¨ë‹¬ ê²€ìƒ‰ ê°€ëŠ¥ (í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€, ì´ë¯¸ì§€â†’í…ìŠ¤íŠ¸)")
        self.embedding_dim = 512

        # ChromaDB ì´ˆê¸°í™” - ìƒˆë¡œìš´ DB ì´ë¦„
        self.client = chromadb.PersistentClient(path="./real_multimodal_db")

        # ì»¬ë ‰ì…˜ ìƒì„± (CLIP 512ì°¨ì›)
        try:
            self.collection = self.client.create_collection(
                name="vision_language_papers",
                metadata={"hnsw:space": "cosine"}
            )
        except:
            self.collection = self.client.get_collection("vision_language_papers")

        # Pinecone ì´ˆê¸°í™” (ì˜µì…˜)
        self.use_pinecone = use_pinecone
        self.pinecone_index = None
        if use_pinecone:
            self._init_pinecone()

    def _init_pinecone(self):
        """Pinecone ì´ˆê¸°í™” (ìµœì‹  API)"""
        try:
            from pinecone import Pinecone, ServerlessSpec

            api_key = os.getenv('PINECONE_API_KEY')
            if not api_key:
                print("âš ï¸  PINECONE_API_KEY not found in .env")
                self.use_pinecone = False
                return

            # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (2024-2025 ìµœì‹ )
            pc = Pinecone(api_key=api_key)

            index_name = "multimodal-papers-clip"

            # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸ ë° ìƒì„± (v5.0.1 compatible)
            existing_indexes = pc.list_indexes()
            index_exists = any(idx.name == index_name for idx in existing_indexes)

            if not index_exists:
                pc.create_index(
                    name=index_name,
                    dimension=self.embedding_dim,  # CLIP 512ì°¨ì›
                    metric='cosine',
                    spec=ServerlessSpec(
                        cloud='aws',
                        region='us-east-1'
                    )
                )
                print(f"âœ… Pinecone ì¸ë±ìŠ¤ '{index_name}' ìƒì„±ë¨")

                # ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                import time
                while not pc.describe_index(index_name).status['ready']:
                    time.sleep(1)
            else:
                print(f"âœ… ê¸°ì¡´ Pinecone ì¸ë±ìŠ¤ '{index_name}' ì‚¬ìš©")

            # ì¸ë±ìŠ¤ ì—°ê²°
            self.pinecone_index = pc.Index(index_name)
            stats = self.pinecone_index.describe_index_stats()
            print(f"   - ì¸ë±ìŠ¤ í†µê³„: {stats['total_vector_count']} vectors")

        except Exception as e:
            print(f"âš ï¸  Pinecone ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.use_pinecone = False

    def process_paper(self, paper_id: str, pdf_path: str, image_dir: str):
        """ë…¼ë¬¸ í•˜ë‚˜ë¥¼ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)"""

        try:
            from text_extractor import extract_text_and_images

            # 1. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
            text, images, captions, featured_image = extract_text_and_images(pdf_path, image_dir)
        except Exception as e:
            print(f"âš ï¸  {paper_id}: ì¶”ì¶œ ì‹¤íŒ¨ - {e}")
            return 0
        
        chunks = []
        embeddings = []
        metadatas = []
        ids = []
        
        # 2. í…ìŠ¤íŠ¸ ì²­í¬ ì²˜ë¦¬
        text_chunks = self._chunk_text(text)
        for i, chunk in enumerate(text_chunks):
            chunk_id = f"{paper_id}_text_{i}"
            
            # CLIP í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_embedding = self.model.encode(chunk)
            
            chunks.append(chunk)
            embeddings.append(text_embedding)
            ids.append(chunk_id)
            metadatas.append({
                'type': 'text',
                'paper_id': paper_id,
                'pdf_path': pdf_path,
                'chunk_index': i
            })
        
        # 3. ì´ë¯¸ì§€ ì²˜ë¦¬ (ì‹¤ì œ ì´ë¯¸ì§€ ì„ë² ë”©)
        for i, img_info in enumerate(images):
            img_path = os.path.join(image_dir, img_info['filename'])
            
            if os.path.exists(img_path):
                # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ìº¡ì…˜ ì°¾ê¸°
                caption = ""
                for cap in captions:
                    if cap.get('page') == img_info.get('page'):
                        caption = cap.get('text', '')
                        break
                
                # CLIPìœ¼ë¡œ ì‹¤ì œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
                image = Image.open(img_path)
                image_embedding = self.model.encode(image)
                
                # ìº¡ì…˜ë„ ë³„ë„ë¡œ ì„ë² ë”©
                if caption:
                    caption_embedding = self.model.encode(caption)
                    # ì´ë¯¸ì§€ì™€ ìº¡ì…˜ ì„ë² ë”©ì„ í‰ê· í•˜ì—¬ í†µí•©
                    combined_embedding = (image_embedding + caption_embedding) / 2
                else:
                    combined_embedding = image_embedding
                
                # ì €ì¥
                img_id = f"{paper_id}_img_{i}"
                chunks.append(f"[IMAGE] {img_info['filename']} - {caption[:200]}")
                embeddings.append(combined_embedding)
                ids.append(img_id)
                metadatas.append({
                    'type': 'image',
                    'paper_id': paper_id,
                    'pdf_path': pdf_path,
                    'image_path': img_path,
                    'page': img_info.get('page', 0),
                    'caption': caption,
                    'filename': img_info['filename']
                })
        
        # 4. DBì— ì €ì¥
        if chunks:
            # ChromaDBì— ì €ì¥
            self.collection.add(
                embeddings=embeddings,
                documents=chunks,
                metadatas=metadatas,
                ids=ids
            )

            # Pineconeì—ë„ ì €ì¥
            if self.use_pinecone and self.pinecone_index:
                try:
                    # Pinecone í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    vectors = []
                    for i, (id_, emb, meta) in enumerate(zip(ids, embeddings, metadatas)):
                        # metadataì— document í…ìŠ¤íŠ¸ ì¶”ê°€
                        meta_copy = meta.copy()
                        meta_copy['text'] = chunks[i][:1000]  # Pinecone ë©”íƒ€ë°ì´í„° ì œí•œìœ¼ë¡œ 1000ìë§Œ

                        vectors.append({
                            'id': id_,
                            'values': emb.tolist() if isinstance(emb, np.ndarray) else emb,
                            'metadata': meta_copy
                        })

                    # ë°°ì¹˜ë¡œ ì—…ì„œíŠ¸ (100ê°œì”©)
                    for i in range(0, len(vectors), 100):
                        batch = vectors[i:i+100]
                        self.pinecone_index.upsert(vectors=batch)

                except Exception as e:
                    print(f"âš ï¸  Pinecone ì €ì¥ ì‹¤íŒ¨: {e}")

            print(f"âœ… {paper_id}: {len(text_chunks)}ê°œ í…ìŠ¤íŠ¸, {len(images)}ê°œ ì´ë¯¸ì§€ ì €ì¥ (ChromaDB + Pinecone)")

        return len(chunks)
    
    def _chunk_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        words = text.split()
        chunks = []
        for i in range(0, len(words), chunk_size):
            chunk = ' '.join(words[i:i+chunk_size])
            chunks.append(chunk)
        return chunks
    
    def search(self, query: str, search_type: str = "all", k: int = 10):
        """
        í†µí•© ê²€ìƒ‰
        search_type: 'all', 'text', 'image'
        """
        # CLIP ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        if query.endswith(('.png', '.jpg', '.jpeg')):
            # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì§ì ‘ ê²€ìƒ‰
            query_image = Image.open(query)
            query_embedding = self.model.encode(query_image)
        else:
            # í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰
            query_embedding = self.model.encode(query)
        
        # ê²€ìƒ‰ í•„í„°
        where = None
        if search_type == "text":
            where = {"type": "text"}
        elif search_type == "image":
            where = {"type": "image"}
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=k,
            where=where
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for i in range(len(results['ids'][0])):
            result = {
                'id': results['ids'][0][i],
                'content': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'distance': results['distances'][0][i],
                'similarity': 1 - results['distances'][0][i]
            }
            
            # ì´ë¯¸ì§€ ê²°ê³¼ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
            if result['metadata']['type'] == 'image':
                result['image_path'] = result['metadata'].get('image_path', '')
                result['caption'] = result['metadata'].get('caption', '')
                result['page'] = result['metadata'].get('page', 0)
            
            formatted_results.append(result)
        
        return formatted_results
    
    def search_similar_images(self, image_path: str, k: int = 10):
        """ìœ ì‚¬í•œ ì´ë¯¸ì§€ ê²€ìƒ‰"""
        # ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ì—¬ ì„ë² ë”©
        image = Image.open(image_path)
        image_embedding = self.model.encode(image)
        
        results = self.collection.query(
            query_embeddings=[image_embedding.tolist()],
            n_results=k,
            where={"type": "image"}
        )
        
        return self._format_results(results)
    
    def _format_results(self, results):
        """ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = []
        for i in range(len(results['ids'][0])):
            formatted.append({
                'id': results['ids'][0][i],
                'content': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'similarity': 1 - results['distances'][0][i]
            })
        return formatted


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Multimodal RAG Builder')
    parser.add_argument('--batch', type=str, help='Batch JSON file')
    parser.add_argument('--search', type=str, help='Search query')
    parser.add_argument('--search-image', type=str, help='Search with image file')
    parser.add_argument('--type', type=str, default='all',
                       choices=['all', 'text', 'image'],
                       help='Search type')
    parser.add_argument('--use-pinecone', action='store_true',
                       help='Also save to Pinecone (requires PINECONE_API_KEY)')

    args = parser.parse_args()

    rag = MultimodalRAGBuilder(use_pinecone=args.use_pinecone)
    
    if args.batch:
        # ë°°ì¹˜ ì²˜ë¦¬
        with open(args.batch, 'r') as f:
            papers = json.load(f)
        
        total_papers = len(papers)
        print(f"\nğŸ“š ì´ {total_papers}ê°œ ë…¼ë¬¸ ì²˜ë¦¬ ì‹œì‘...")

        for i, paper in enumerate(papers, 1):
            paper_id = paper.get('paper_id')
            pdf_path = paper.get('pdf_path')
            image_dir = f"./extracted_images/{paper_id}"

            if os.path.exists(pdf_path):
                print(f"\n[{i}/{total_papers}] Processing {paper_id}...")
                try:
                    rag.process_paper(paper_id, pdf_path, image_dir)
                except Exception as e:
                    print(f"âš ï¸  {paper_id}: ì²˜ë¦¬ ì‹¤íŒ¨ - {e}")
                    continue
            else:
                print(f"[{i}/{total_papers}] PDF not found: {pdf_path}")
    
    elif args.search:
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        results = rag.search(args.search, search_type=args.type)
        
        print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼: '{args.search}'")
        print("=" * 60)
        
        for i, result in enumerate(results[:5], 1):
            print(f"\n{i}. [{result['metadata']['type'].upper()}]")
            print(f"   ë…¼ë¬¸: {result['metadata']['paper_id']}")
            print(f"   ìœ ì‚¬ë„: {result['similarity']:.3f}")
            
            if result['metadata']['type'] == 'image':
                print(f"   ì´ë¯¸ì§€: {result['metadata']['filename']}")
                print(f"   í˜ì´ì§€: {result['metadata']['page']}")
                print(f"   ìº¡ì…˜: {result['metadata'].get('caption', 'N/A')[:100]}...")
            else:
                print(f"   ë‚´ìš©: {result['content'][:200]}...")
    
    elif args.search_image:
        # ì´ë¯¸ì§€ë¡œ ê²€ìƒ‰
        results = rag.search_similar_images(args.search_image)
        
        print(f"\nğŸ–¼ï¸ ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰: {args.search_image}")
        print("=" * 60)
        
        for i, result in enumerate(results[:5], 1):
            print(f"\n{i}. ë…¼ë¬¸: {result['metadata']['paper_id']}")
            print(f"   ì´ë¯¸ì§€: {result['metadata']['filename']}")
            print(f"   í˜ì´ì§€: {result['metadata']['page']}")
            print(f"   ìœ ì‚¬ë„: {result['similarity']:.3f}")
            print(f"   ìº¡ì…˜: {result['metadata'].get('caption', 'N/A')[:100]}...")