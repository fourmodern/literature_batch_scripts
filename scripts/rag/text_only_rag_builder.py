"""
Vector Database Builder for RAG System
ë…¼ë¬¸ PDFë¥¼ ë²¡í„° DBë¡œ ë³€í™˜í•˜ì—¬ RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•
"""

import os
import sys
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from datetime import datetime
import numpy as np

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# Vector DB options
try:
    import chromadb
    from chromadb.config import Settings
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False

try:
    from pinecone import Pinecone, ServerlessSpec
    PINECONE_AVAILABLE = True
except ImportError:
    PINECONE_AVAILABLE = False

# Embedding models
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from text_extractor import extract_text_from_pdf, extract_text_and_images


class TextChunker:
    """ë…¼ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ì²­í¬ë¡œ ë¶„í• """
    
    @staticmethod
    def chunk_by_sections(text: str, chunk_size: int = 1000, 
                          overlap: int = 200) -> List[Dict]:
        """
        ì„¹ì…˜ë³„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        í•™ìˆ  ë…¼ë¬¸ì˜ êµ¬ì¡°ë¥¼ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ì²­í‚¹
        """
        chunks = []
        
        # ì„¹ì…˜ ë§ˆì»¤ ì •ì˜
        section_markers = [
            'abstract', 'introduction', 'background', 'related work',
            'methodology', 'methods', 'materials and methods',
            'results', 'experiments', 'evaluation',
            'discussion', 'conclusion', 'future work',
            'references', 'appendix'
        ]
        
        lines = text.split('\n')
        current_section = 'unknown'
        section_text = []
        
        for line in lines:
            lower_line = line.lower().strip()
            
            # ìƒˆ ì„¹ì…˜ ê°ì§€
            section_found = False
            for marker in section_markers:
                if marker in lower_line and len(lower_line) < 50:
                    # ì´ì „ ì„¹ì…˜ ì²˜ë¦¬
                    if section_text:
                        section_content = '\n'.join(section_text)
                        chunks.extend(
                            TextChunker._split_section(
                                section_content, 
                                current_section, 
                                chunk_size, 
                                overlap
                            )
                        )
                    
                    # ìƒˆ ì„¹ì…˜ ì‹œì‘
                    current_section = marker
                    section_text = [line]
                    section_found = True
                    break
            
            if not section_found:
                section_text.append(line)
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì²˜ë¦¬
        if section_text:
            section_content = '\n'.join(section_text)
            chunks.extend(
                TextChunker._split_section(
                    section_content, 
                    current_section, 
                    chunk_size, 
                    overlap
                )
            )
        
        return chunks
    
    @staticmethod
    def _split_section(text: str, section_name: str, 
                       chunk_size: int, overlap: int) -> List[Dict]:
        """ì„¹ì…˜ì„ ì²­í¬ë¡œ ë¶„í• """
        chunks = []
        words = text.split()
        
        if len(words) == 0:
            return chunks
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk_words = words[i:i + chunk_size]
            chunk_text = ' '.join(chunk_words)
            
            chunks.append({
                'text': chunk_text,
                'section': section_name,
                'word_count': len(chunk_words),
                'char_count': len(chunk_text),
                'chunk_index': len(chunks)
            })
        
        return chunks
    
    @staticmethod
    def chunk_by_paragraphs(text: str, min_size: int = 100, 
                           max_size: int = 500) -> List[Dict]:
        """
        ë‹¨ë½ ë‹¨ìœ„ë¡œ ì²­í‚¹ (ìì—°ìŠ¤ëŸ¬ìš´ ì˜ë¯¸ ë‹¨ìœ„ ë³´ì¡´)
        """
        chunks = []
        paragraphs = text.split('\n\n')
        
        current_chunk = []
        current_size = 0
        
        for para in paragraphs:
            para_size = len(para.split())
            
            if current_size + para_size > max_size and current_chunk:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                chunks.append({
                    'text': '\n\n'.join(current_chunk),
                    'word_count': current_size,
                    'chunk_index': len(chunks)
                })
                current_chunk = [para]
                current_size = para_size
            else:
                current_chunk.append(para)
                current_size += para_size
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
        if current_chunk:
            chunks.append({
                'text': '\n\n'.join(current_chunk),
                'word_count': current_size,
                'chunk_index': len(chunks)
            })
        
        return chunks


class EmbeddingGenerator:
    """í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±"""
    
    def __init__(self, model_type: str = "sentence-transformers"):
        self.model_type = model_type
        
        if model_type == "sentence-transformers" and SENTENCE_TRANSFORMERS_AVAILABLE:
            # í•œêµ­ì–´/ì˜ì–´ ë‹¤êµ­ì–´ ëª¨ë¸
            self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        elif model_type == "clip" and SENTENCE_TRANSFORMERS_AVAILABLE:
            # CLIP ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€)
            self.model = SentenceTransformer('clip-ViT-B-32-multilingual-v1')
            print("âœ… Using CLIP multimodal model for text+image embeddings")
        elif model_type == "openai" and OPENAI_AVAILABLE:
            self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        else:
            raise ValueError(f"Embedding model {model_type} not available")
    
    def generate_embeddings(self, texts: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
        if self.model_type in ["sentence-transformers", "clip"]:
            return self.model.encode(texts, show_progress_bar=True)
        
        elif self.model_type == "openai":
            embeddings = []
            for text in texts:
                response = self.client.embeddings.create(
                    model="text-embedding-3-small",
                    input=text[:8000]  # OpenAI ì„ë² ë”© ê¸¸ì´ ì œí•œ
                )
                embeddings.append(response.data[0].embedding)
            return np.array(embeddings)
    
    def generate_image_embeddings(self, image_paths: List[str]) -> np.ndarray:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (CLIP ëª¨ë¸ìš©)"""
        if self.model_type == "clip":
            from PIL import Image
            images = []
            for path in image_paths:
                try:
                    img = Image.open(path)
                    images.append(img)
                except:
                    # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ì‹œ ë¹ˆ ì´ë¯¸ì§€ ì‚¬ìš©
                    images.append(Image.new('RGB', (224, 224), color='white'))
            return self.model.encode(images, show_progress_bar=True)
        else:
            raise ValueError(f"Image embedding not supported for {self.model_type}")


class VectorDBManager:
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self, db_type: str = "chroma", persist_dir: str = "./vector_db"):
        self.db_type = db_type
        self.persist_dir = Path(persist_dir)
        self.persist_dir.mkdir(exist_ok=True)
        
        if db_type == "chroma" and CHROMA_AVAILABLE:
            self.client = chromadb.PersistentClient(
                path=str(self.persist_dir),
                settings=Settings(anonymized_telemetry=False)
            )
            self.collection = None
        elif db_type == "pinecone" and PINECONE_AVAILABLE:
            # Pinecone ì´ˆê¸°í™” (ìƒˆë¡œìš´ SDK ë°©ì‹)
            self.pc = Pinecone(
                api_key=os.getenv("PINECONE_API_KEY")
            )
            self.index_name = os.getenv("PINECONE_INDEX_NAME", "literature-rag")
            self.index = None
        else:
            raise ValueError(f"Vector DB {db_type} not available")
    
    def create_collection(self, name: str = "papers"):
        """ì»¬ë ‰ì…˜/ì¸ë±ìŠ¤ ìƒì„±"""
        if self.db_type == "chroma":
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
            try:
                self.client.delete_collection(name)
            except:
                pass
            
            self.collection = self.client.create_collection(
                name=name,
                metadata={"hnsw:space": "cosine"}
            )
            
        elif self.db_type == "pinecone":
            # Pinecone ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ì—°ê²°
            existing_indexes = [idx.name for idx in self.pc.list_indexes()]
            
            if self.index_name not in existing_indexes:
                print(f"Creating new Pinecone index: {self.index_name}")
                self.pc.create_index(
                    name=self.index_name,
                    dimension=384,  # sentence-transformers ì°¨ì›
                    metric="cosine",
                    spec=ServerlessSpec(
                        cloud="aws",
                        region="us-east-1"  # ë¬´ë£Œ í”Œëœ ì§€ì› ë¦¬ì „
                    )
                )
                # ì¸ë±ìŠ¤ ìƒì„± ëŒ€ê¸°
                import time
                time.sleep(10)
            
            self.index = self.pc.Index(self.index_name)
            print(f"âœ… Connected to Pinecone index: {self.index_name}")
            
            # ì¸ë±ìŠ¤ í†µê³„ ì¶œë ¥
            stats = self.index.describe_index_stats()
            print(f"   Vectors in index: {stats.get('total_vector_count', 0)}")
    
    def add_documents(self, chunks: List[Dict], embeddings: np.ndarray, 
                     metadata: Dict):
        """ë¬¸ì„œ ì²­í¬ì™€ ì„ë² ë”©ì„ DBì— ì¶”ê°€"""
        if self.db_type == "chroma":
            if not self.collection:
                self.create_collection()
            
            # ChromaDBì— ì¶”ê°€
            ids = [f"{metadata['paper_id']}_{i}" for i in range(len(chunks))]
            
            metadatas = []
            for i, chunk in enumerate(chunks):
                # metadataì˜ dict ê°’ë“¤ì„ í”Œë«í•˜ê²Œ ë³€í™˜
                flat_metadata = {}
                for key, value in metadata.items():
                    if isinstance(value, dict):
                        # dictì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê±°ë‚˜ ê°œë³„ í•„ë“œë¡œ ë¶„ë¦¬
                        if key == 'metadata':
                            flat_metadata['filename'] = value.get('filename', 'unknown')
                            flat_metadata['storage_key'] = value.get('storage_key', 'unknown')
                        else:
                            flat_metadata[key] = str(value)
                    elif value is None:
                        flat_metadata[key] = ''
                    else:
                        flat_metadata[key] = value
                
                chunk_metadata = {
                    **flat_metadata,
                    'chunk_index': i,
                    'section': chunk.get('section', 'unknown'),
                    'word_count': chunk.get('word_count', 0)
                }
                metadatas.append(chunk_metadata)
            
            self.collection.add(
                embeddings=embeddings.tolist(),
                documents=[chunk['text'] for chunk in chunks],
                metadatas=metadatas,
                ids=ids
            )
            
        elif self.db_type == "pinecone":
            if not self.index:
                self.create_collection()
            
            # Pineconeì— ì¶”ê°€ (ìƒˆë¡œìš´ í˜•ì‹)
            vectors = []
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                vector_id = f"{metadata['paper_id']}_{i}"
                
                # ë©”íƒ€ë°ì´í„° í¬ê¸° ì œí•œ (40KB)
                chunk_text = chunk['text'][:2000]  # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                vector_metadata = {
                    'paper_id': metadata.get('paper_id', ''),
                    'title': metadata.get('title', '')[:200],
                    'authors': str(metadata.get('authors', []))[:500],
                    'year': str(metadata.get('year', '')),
                    'text': chunk_text,
                    'section': chunk.get('section', 'unknown'),
                    'chunk_index': i,
                    'word_count': chunk.get('word_count', 0)
                }
                
                vectors.append({
                    "id": vector_id,
                    "values": embedding.tolist(),
                    "metadata": vector_metadata
                })
            
            # ë°°ì¹˜ë¡œ ì—…ë¡œë“œ (100ê°œì”©)
            batch_size = 100
            for i in range(0, len(vectors), batch_size):
                batch = vectors[i:i+batch_size]
                self.index.upsert(vectors=batch)
            
            print(f"   Uploaded {len(vectors)} vectors to Pinecone")
    
    def search(self, query: str, embedder: EmbeddingGenerator, 
              k: int = 5) -> List[Dict]:
        """ì¿¼ë¦¬ë¡œ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰"""
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = embedder.generate_embeddings([query])[0]
        
        if self.db_type == "chroma":
            if not self.collection:
                raise ValueError("Collection not initialized")
            
            results = self.collection.query(
                query_embeddings=[query_embedding.tolist()],
                n_results=k
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            for i in range(len(results['ids'][0])):
                formatted_results.append({
                    'id': results['ids'][0][i],
                    'text': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i] if 'distances' in results else None
                })
            
            return formatted_results
            
        elif self.db_type == "pinecone":
            if not self.index:
                self.create_collection()
            
            # Pinecone ì¿¼ë¦¬ (ìƒˆë¡œìš´ í˜•ì‹)
            results = self.index.query(
                vector=query_embedding.tolist(),
                top_k=k,
                include_metadata=True
            )
            
            formatted_results = []
            for match in results['matches']:
                formatted_results.append({
                    'id': match['id'],
                    'text': match['metadata'].get('text', ''),
                    'metadata': match['metadata'],
                    'distance': 1 - match['score']  # cosine similarity to distance
                })
            
            return formatted_results


class PaperRAGBuilder:
    """ë…¼ë¬¸ RAG ì‹œìŠ¤í…œ êµ¬ì¶• í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, db_type: str = "chroma", 
                 embedding_model: str = "sentence-transformers"):
        self.db_manager = VectorDBManager(db_type)
        self.embedder = EmbeddingGenerator(embedding_model)
        self.chunker = TextChunker()
        self.processed_papers = self._load_processed_papers()
    
    def _load_processed_papers(self) -> set:
        """ì´ë¯¸ ì²˜ë¦¬ëœ ë…¼ë¬¸ ëª©ë¡ ë¡œë“œ"""
        processed_file = Path("./vector_db/processed_papers.json")
        if processed_file.exists():
            with open(processed_file, 'r') as f:
                return set(json.load(f))
        return set()
    
    def _save_processed_papers(self):
        """ì²˜ë¦¬ëœ ë…¼ë¬¸ ëª©ë¡ ì €ì¥"""
        processed_file = Path("./vector_db/processed_papers.json")
        processed_file.parent.mkdir(exist_ok=True)
        with open(processed_file, 'w') as f:
            json.dump(list(self.processed_papers), f)
    
    def process_pdf(self, pdf_path: str, metadata: Dict) -> bool:
        """PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° DBì— ì¶”ê°€"""
        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
        paper_id = metadata.get('key', hashlib.md5(pdf_path.encode()).hexdigest())
        if paper_id in self.processed_papers:
            print(f"âœ“ Already processed: {paper_id}")
            return False
        
        try:
            # 1. í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì¶”ì¶œ
            print(f"ğŸ“„ Extracting text and images from {pdf_path}")
            
            # ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬
            image_dir = f"./extracted_images/{paper_id}"
            os.makedirs(image_dir, exist_ok=True)
            
            # extract_text_and_images í•¨ìˆ˜ ì‚¬ìš©
            text, images, captions, featured_image = extract_text_and_images(pdf_path, image_dir)
            
            if len(text) < 100:
                print(f"âš ï¸ Text too short, skipping")
                return False
            
            print(f"  ğŸ“ Text: {len(text)} chars")
            print(f"  ğŸ–¼ï¸ Images: {len(images)} found")
            print(f"  ğŸ“Œ Captions: {len(captions)} found")
            
            # 2. í…ìŠ¤íŠ¸ ì²­í‚¹
            print(f"âœ‚ï¸ Chunking content...")
            text_chunks = self.chunker.chunk_by_sections(text, chunk_size=500, overlap=50)
            
            # ì´ë¯¸ì§€ì™€ ìº¡ì…˜ì„ ì¶”ê°€ ì²­í¬ë¡œ ìƒì„±
            all_chunks = text_chunks.copy()
            
            # ì´ë¯¸ì§€ ì •ë³´ë¥¼ ì²­í¬ë¡œ ì¶”ê°€ (ë…¼ë¬¸ ì •ë³´ í¬í•¨)
            for idx, img in enumerate(images):
                img_text = f"[IMAGE {idx+1}] "
                img_text += f"Paper ID: {paper_id}, "
                img_text += f"PDF: {os.path.basename(pdf_path)}, "
                img_text += f"Page {img.get('page', '?')}, "
                img_text += f"File: {img.get('filename', 'unknown')}"
                
                # ê´€ë ¨ ìº¡ì…˜ ì°¾ê¸°
                for cap in captions:
                    if cap.get('page') == img.get('page'):
                        img_text += f"\nCaption: {cap.get('text', '')}"
                        break
                
                all_chunks.append({
                    'text': img_text,
                    'section': 'image',
                    'metadata': {'type': 'image', 'index': idx}
                })
            
            # ìº¡ì…˜ì„ ë³„ë„ ì²­í¬ë¡œ ì¶”ê°€
            for idx, cap in enumerate(captions):
                cap_text = f"[{cap.get('type', 'FIGURE').upper()} CAPTION] "
                cap_text += f"Page {cap.get('page', '?')}: "
                cap_text += cap.get('text', '')
                
                all_chunks.append({
                    'text': cap_text,
                    'section': 'caption',
                    'metadata': {'type': 'caption', 'index': idx}
                })
            
            chunks = all_chunks
            print(f"  Created {len(chunks)} total chunks (text + images + captions)")
            
            # 3. ì„ë² ë”© ìƒì„±
            print(f"ğŸ§® Generating embeddings...")
            texts = [chunk['text'] for chunk in chunks]
            embeddings = self.embedder.generate_embeddings(texts)
            
            # 4. DBì— ì €ì¥
            print(f"ğŸ’¾ Saving to vector DB...")
            enhanced_metadata = {
                **metadata,
                'paper_id': paper_id,
                'pdf_path': pdf_path,
                'processed_at': datetime.now().isoformat(),
                'total_chunks': len(chunks)
            }
            
            self.db_manager.add_documents(chunks, embeddings, enhanced_metadata)
            
            # 5. ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
            self.processed_papers.add(paper_id)
            self._save_processed_papers()
            
            print(f"âœ… Successfully processed: {paper_id}")
            return True
            
        except Exception as e:
            print(f"âŒ Error processing {pdf_path}: {e}")
            return False
    
    def batch_process_papers(self, papers: List[Dict]) -> Dict:
        """ì—¬ëŸ¬ ë…¼ë¬¸ ì¼ê´„ ì²˜ë¦¬"""
        results = {
            'success': 0,
            'failed': 0,
            'skipped': 0
        }
        
        for paper in papers:
            pdf_path = paper.get('pdf_path')
            if not pdf_path or not os.path.exists(pdf_path):
                results['skipped'] += 1
                continue
            
            if self.process_pdf(pdf_path, paper):
                results['success'] += 1
            else:
                results['failed'] += 1
        
        return results
    
    def search_papers(self, query: str, k: int = 5) -> List[Dict]:
        """ë…¼ë¬¸ ê²€ìƒ‰"""
        return self.db_manager.search(query, self.embedder, k)


# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Build vector DB for papers')
    parser.add_argument('--pdf', type=str, help='Single PDF to process')
    parser.add_argument('--batch', type=str, help='JSON file with paper list')
    parser.add_argument('--search', type=str, help='Search query')
    parser.add_argument('--db', type=str, default='chroma', 
                       choices=['chroma', 'pinecone'])
    parser.add_argument('--embedding', type=str, default='sentence-transformers',
                       choices=['sentence-transformers', 'openai'])
    
    args = parser.parse_args()
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag_builder = PaperRAGBuilder(db_type=args.db, embedding_model=args.embedding)
    
    if args.pdf:
        # ë‹¨ì¼ PDF ì²˜ë¦¬
        metadata = {
            'title': Path(args.pdf).stem,
            'source': 'manual'
        }
        rag_builder.process_pdf(args.pdf, metadata)
        
    elif args.batch:
        # ë°°ì¹˜ ì²˜ë¦¬
        with open(args.batch, 'r') as f:
            papers = json.load(f)
        results = rag_builder.batch_process_papers(papers)
        print(f"\nğŸ“Š Batch processing results:")
        print(f"  âœ… Success: {results['success']}")
        print(f"  âŒ Failed: {results['failed']}")
        print(f"  â­ï¸ Skipped: {results['skipped']}")
        
    elif args.search:
        # ê²€ìƒ‰
        rag_builder.db_manager.create_collection()  # ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ
        results = rag_builder.search_papers(args.search)
        
        print(f"\nğŸ” Search results for: '{args.search}'")
        print("=" * 60)
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result['metadata'].get('title', 'Unknown')}")
            print(f"   Section: {result['metadata'].get('section', 'unknown')}")
            print(f"   Text: {result['text'][:200]}...")
            if 'distance' in result:
                print(f"   Similarity: {1 - result['distance']:.3f}")